在写这备忘的时候，仍在下载漫画中。。。

首先这篇文章讲的是如何使用Scrapy批量下载海贼王漫画。

### 准备

Scrapy环境安装

此处略去，直奔主题


### 抓取代码

抓取的樱花漫画网站的海贼王漫画

网址

```
start_urls = ['http://sakuramanga.net/truyen-tranh-tieng-nhat-japanese-manga/one-piece-truyen-tranh-tieng-nhat/']

```

spider的parse代码：

```
    def parse(self, response):
        list = response.xpath('//*[@id="blog-wrapper"]/article/header/div/a/@href').extract()

        for url in list:
            print(url)
            yield Request(url, callback=self.parse_item, dont_filter=True)

    def parse_item(self, response):
        print("---------parse item----------")
        titles = response.xpath('//*[@class="entry-content"]/p/img/@src').extract()
        imgs = response.xpath('//*[@class="entry-content"]/img/@src').extract()

        chapter = response.xpath('//*[@class="entry-title"]/text()').extract()
        c = ''.join(chapter)
        c = c.strip()
        print(c)
        item = OnepieceItem()
        item['chapter'] = c
        item['image_urls'] = imgs + titles

        return item

```

items.py

```

class OnepieceItem(scrapy.Item):
    # define the fields for your item here like:
    chapter = scrapy.Field()
    image_urls = scrapy.Field()
    images = scrapy.Field()
```

pipelines.py

```
# 继承ImagesPipeline
class OnepiecePipeline(ImagesPipeline):

    def get_media_requests(self, item, info):
        for image_url in item['image_urls']:
            print(image_url)
            yield Request(image_url, meta={'item': item})

    # 设置图片名字，保存路径
    def file_path(self, request, response=None, info=None):
        item = request.meta['item']  # 通过上面的meta传递过来item
        name = request.url.split('/')[-1]
        print(name)
        down_file_name = 'full/{0}/{1}'.format(item['chapter'], name)
        return down_file_name

```

settings.py添加下面属性

```
ITEM_PIPELINES = {
   'onepiece.pipelines.OnepiecePipeline': 300,
}

IMAGES_STORE = 'image'
```

源码：
https://github.com/doublechoose/onepiece
